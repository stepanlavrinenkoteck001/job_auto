{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "# import spacy_cleaner\n",
    "# from spacy_cleaner.processing import removers, replacers, mutators\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "# from src.utils.logging_utils import create_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder_path = Path().cwd().parent\n",
    "prep_data_path = parent_folder_path / 'data' / 'job_posts'/ 'prep_data'\n",
    "model_path = parent_folder_path / 'data' / 'job_posts'/ 'artifacts' / 'gpt_models'\n",
    "job_descr_path = parent_folder_path / 'data' /'job_posts'/ 'original_data/jd1.json'\n",
    "\n",
    "## chatgpt vs gpt4all constants\n",
    "# gpt_output_path = prep_data_path / 'chatgpt_output.csv'\n",
    "# gpt_model = gpt_model_str = \"gpt-3.5-turbo\"\n",
    "gpt_output_path = prep_data_path /'gpt4all_output.csv'\n",
    "gpt_model_str = 'ggml-gpt4all-j-v1.3-groovy'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_string = 'I am looking for a job. List the skills you need to apply to this job posting: '\n",
    "# question_string = 'what do I need to know in order to apply to this job: '\n",
    "# question_string = 'What qualifications do I need to have in order to apply to this job: '\n",
    "\n",
    "# question_string = 'List the hard skills needed to apply to the job posting above as bulletpoints'\n",
    "# question_string = 'List the hard tech skills, responsibilities and technical tool knowledge the job posting above requires.'\n",
    "question_string = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_string = \"Act like a researcher. Give me a list of keywords for a job description I will provide you with that I can use to find a candidate for the position. Act like an expert in this field, include additional keywords that may not be in the job description.\"\n",
    "user_string = 'List the hard tech skills, responsibilities and technical tool knowledge the job posting above requires.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class jobPostIingest:\n",
    "    \"\"\"\n",
    "    Ingestion of job posts, feeding in only the ones that haven't yet been processed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, job_descr_path: str, gpt_output_path: str):\n",
    "        self.job_descr_path = job_descr_path\n",
    "        self.gpt_output_path = gpt_output_path\n",
    "\n",
    "    def ingest_jp(self):\n",
    "        \"\"\"\n",
    "        Reads job descriptions from a JSON file at `job_descr_path` and appends any new responses generated by ChatGPT to the end of the file. \n",
    "        Removes duplicate rows based on all columns except 'salaries' and 'skill_summary'.\n",
    "\n",
    "        \n",
    "        Args:\n",
    "            job_descr_path (str): Path to JSON file containing job descriptions.\n",
    "            gpt_output_path (str): Path to CSV file containing ChatGPT responses.\n",
    "        \n",
    "        Returns:\n",
    "            pandas.DataFrame: A merged DataFrame containing unique rows of job descriptions and ChatGPT responses.\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_json(job_descr_path)\n",
    "        column_mask = (df.columns != 'salaries') & (df.columns != f'skill_summary')\n",
    "        df = df.drop_duplicates(subset = df.columns[column_mask])\n",
    "        if gpt_output_path.exists():\n",
    "            df_gpt = pd.read_csv(gpt_output_path)\n",
    "            df = pd.concat([df,df_gpt]).drop_duplicates(subset = df.columns[column_mask], keep = False)\n",
    "        return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt4all\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "from abc import ABC, abstractclassmethod\n",
    "\n",
    "class abstractGptModel(ABC):\n",
    "    \n",
    "    @abstractclassmethod\n",
    "    def gpt_prompt_return():\n",
    "        pass\n",
    "\n",
    "class gpt4All(abstractGptModel):\n",
    "    \"\"\"Wrapper class for the GPT-4 All model from gpt4all.\n",
    "\n",
    "    Attributes:\n",
    "        gpt_model_str (str): The name of the GPT-4 All model to use.\n",
    "        model_path (Path): The path to the directory containing the model files.\n",
    "\n",
    "    Methods:\n",
    "        gpt_prompt_return(message_dict: List[Dict[str, str]]) -> str:\n",
    "            Given a list of message dictionaries, returns the completion generated by the GPT-4 All model.\n",
    "            Each message dictionary should have a 'speaker' key indicating which speaker the message is from,\n",
    "            and a 'text' key containing the text of the message.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gpt_model_str: str, model_path: Path) -> None:\n",
    "        \"\"\"Creates a new gpt4All instance.\n",
    "\n",
    "        Args:\n",
    "            gpt_model_str (str): The name of the GPT-4 All model to use.\n",
    "            model_path (Path): The path to the directory containing the model files.\n",
    "        \"\"\"\n",
    "        self.gpt_model_str = gpt_model_str\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def gpt_prompt_return(self, prompt: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"Given a list of message dictionaries, returns the completion generated by the GPT-4 All model.\n",
    "\n",
    "        Args:\n",
    "            message_dict (List[Dict[str, str]]): A list of message dictionaries.\n",
    "                Each dictionary should have a 'speaker' key indicating which speaker the message is from,\n",
    "                and a 'text' key containing the text of the message.\n",
    "\n",
    "        Returns:\n",
    "            str: The completion generated by the GPT-4 All model.\n",
    "        \"\"\"\n",
    "        gpt_model = gpt4all.GPT4All(self.gpt_model_str, model_path=str(self.model_path))\n",
    "        out = gpt_model.chat_completion(default_prompt_footer=False,\n",
    "                                         default_prompt_header=False,\n",
    "                                         messages=prompt,\n",
    "                                         verbose=False,\n",
    "                                         streaming=False)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class chatGpt(abstractGptModel):\n",
    "    \"\"\"Wrapper class for the GPT model from chatgpt.\n",
    "\n",
    "    Attributes:\n",
    "        gpt_model_str (str): The name of the GPT model (3/3.5/4) to use.\n",
    "        model_path (Path): The path to the directory containing the model files.\n",
    "\n",
    "    Methods:\n",
    "        gpt_prompt_return(message_dict: List[Dict[str, str]]) -> str:\n",
    "            Given a list of message dictionaries, returns the completion generated by the GPT model.\n",
    "            Each message dictionary should have a 'speaker' key indicating which speaker the message is from,\n",
    "            and a 'text' key containing the text of the message.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gpt_model_str: str, model_path: None) -> None:\n",
    "        \"\"\"Creates a new chatGpt instance.\n",
    "\n",
    "        Args:\n",
    "            gpt_model_str (str): The name of the chatgpt model (3/3.5/4) to use.\n",
    "            model_path (Path): The path to the directory containing the model files.\n",
    "        \"\"\"\n",
    "        self.gpt_model_str = gpt_model_str\n",
    "\n",
    "    @staticmethod\n",
    "    def get_key_from_env() -> None:\n",
    "        \"\"\"\n",
    "        Set api key from .env file. This file should contain an entry OPENAI_API_KEY = 'xxx'\n",
    "        \"\"\"\n",
    "        load_dotenv()\n",
    "        openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "\n",
    "    def gpt_prompt_return(self, prompt: List[Dict[str, str]]) -> str:\n",
    "        \"\"\"Given a list of message dictionaries, returns the completion generated by the GPT-4 All model.\n",
    "\n",
    "        Args:\n",
    "            message_dict (List[Dict[str, str]]): A list of message dictionaries.\n",
    "                Each dictionary should have a 'speaker' key indicating which speaker the message is from,\n",
    "                and a 'text' key containing the text of the message.\n",
    "\n",
    "        Returns:\n",
    "            str: The completion generated by the chatgpt model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.get_key_from_env()  # set api key\n",
    "            out = openai.ChatCompletion.create(\n",
    "                model= gpt_model_str,\n",
    "                messages=prompt\n",
    "                )\n",
    "            time.sleep(25)  # free account has throughput limitations. This spreads throughput out for free key\n",
    "        except:\n",
    "            time.sleep(60*30)   # after n amount of prompts, free account time out to give priority to paid accounts. This will wait untill free accounts can work again \n",
    "            out = openai.ChatCompletion.create(\n",
    "                model= gpt_model_str,\n",
    "                messages=prompt\n",
    "                )\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gptPredict:\n",
    "    \"\"\"\n",
    "    This class applies a GPT language model to generate text predictions based on a provided input and saves the \n",
    "    results to a CSV file. \n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the data to be processed.\n",
    "        model (abstractGptModel): An instance of an abstractGptModel object representing the GPT language model to be used.\n",
    "        system_string (str): A string message from the system that will introduce each text prediction prompt.\n",
    "        user_string (str): A string message from the user that will be appended to the end of each text prediction prompt.\n",
    "        gpt_output_path (Path): A pathlib.Path object representing the path where the generated text predictions \n",
    "                                should be saved as a CSV file.\n",
    "\n",
    "    Attributes:\n",
    "        model (abstractGptModel): The instance of the abstractGptModel object representing the GPT language model being used.\n",
    "        system_string (str): A string message from the system that introduces each text prediction prompt.\n",
    "        user_string (str): A string message from the user that is appended to the end of each text prediction prompt.\n",
    "        gpt_output_path (Path): A pathlib.Path object representing the path where the generated text predictions \n",
    "                                should be saved as a CSV file.\n",
    "        df (pd.DataFrame): The pandas DataFrame containing the data to be processed.\n",
    "        prompt (List[Dict[str, str]]): A list of message dictionaries with a user message and speaker role for use in generating text predictions.\n",
    "\n",
    "    Methods:\n",
    "        message_dict(self, description) -> List[Dict[str, str]]:\n",
    "            Build chatgpt-acceptable dictionary input with a user message.\n",
    "\n",
    "        gpt_out_return(self, description: str) -> str:\n",
    "            Generate a text prediction using the GPT language model for a given prompt string. Returns the generated text prediction.\n",
    "\n",
    "        gpt_prompt(self, df_row: pd.Series) -> str:\n",
    "            Generates a text prediction using the GPT language model for a given row of data in the pandas DataFrame. Returns the generated text prediction.\n",
    "\n",
    "        gpt_prompt_save_csv(self, df_row: pd.Series) -> None:\n",
    "            Generates a text prediction using the GPT language model for a given row of data in the pandas DataFrame and saves the result to the specified CSV file.\n",
    "\n",
    "        apply_lambda_save_csv(self):\n",
    "            Applies the gpt_prompt_save_csv method to each row of data in the pandas DataFrame and saves the resulting text predictions to the specified CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, model: abstractGptModel, system_string: str, user_string: str, gpt_output_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Initializes an instance of the gptPredict class.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A pandas DataFrame containing job descriptions to analyze.\n",
    "            model (abstractGptModel): An instance of a class implementing the abstractGptModel interface.\n",
    "            system_string (str): A string representing the system prompt when interacting with chatgpt model.\n",
    "            user_string (str): A string representing the user input prompt for entering job description in chatgpt model.\n",
    "            gpt_output_path (Path): A Path object representing the location where the gpt model generated output is to be saved.\n",
    "        \"\"\"\n",
    "\n",
    "        self.model = model\n",
    "        self.system_string = system_string\n",
    "        self.user_string = user_string\n",
    "        self.gpt_output_path = gpt_output_path\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "\n",
    "    def message_dict(self, description) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Builds a chatgpt-compatible dictionary input with a user message.\n",
    "\n",
    "        Args:\n",
    "            description (str): A string representing a job description.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict[str, str]]: A list of message dictionaries. Each dictionary should have a 'speaker' key indicating which speaker the message is from, and a 'text' key containing the text of the message.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # return [{\"role\": \"system\", \"content\": \"Act like a researcher. Give me a list of keywords for a job description I will provide you with that I can use to find a candidate for the position. Act like an expert in this field, include additional keywords that may not be in the job description.\"},\n",
    "        #         {\"role\": \"user\", \"content\": prompt_str(description, question_string)}]\n",
    "        # return [{\"role\": \"system\", \"content\": \"Act like a researcher. Give me a list of keywords for a job description I will provide you with that I can use to find a candidate for the position. Act like an expert in this field, include additional keywords that may not be in the job description.\"},\n",
    "        #         {\"role\": \"user\", \"content\": description}] \n",
    "        self.prompt =  [{\"role\": \"system\", \"content\": self.system_string},\n",
    "                        {\"role\": \"user\", \"content\": description + '. ' + self.user_string}] \n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "    def gpt_prompt(self, df_row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Generates a GPT model completion for a given DataFrame row containing a job description.\n",
    "        In case of an empty string, a period or None it returns an empty string\n",
    "\n",
    "        Args:\n",
    "            df_row (pd.Series): A series representing a single row of a pandas DataFrame containing job descriptions.\n",
    "\n",
    "        Returns:\n",
    "            str: The completion generated by the chatgpt model.\n",
    "        \"\"\"\n",
    "\n",
    "        out = self.message_dict(df_row['description']).model.gpt_prompt_return(self.prompt)\n",
    "        try:\n",
    "            ret = str(out[\"choices\"][0][\"message\"]['content'])\n",
    "            if ret == '.' or ret == 'None':\n",
    "                # can also try cleaning up with spacy\n",
    "                ret = ''\n",
    "            return ret\n",
    "        except:\n",
    "            return ''\n",
    "   \n",
    "\n",
    "\n",
    "    def gpt_prompt_save_csv(self, df_row: pd.Series) -> None:\n",
    "        \"\"\"\n",
    "        Generate a GPT model completion for a given DataFrame row containing a job description and append the result to a specified CSV file.\n",
    "\n",
    "        Args:\n",
    "            df_row (pd.Series): A series representing a single row of a pandas DataFrame containing job descriptions.\n",
    "        \"\"\"\n",
    "\n",
    "        df_row[f'hard_skills_{gpt_model_str}'] = self.gpt_prompt(df_row)\n",
    "\n",
    "        header_t_or_f = False if self.gpt_output_path.exists() else True \n",
    "        df_row.to_frame().T.to_csv(path_or_buf=self.gpt_output_path, \n",
    "                                    mode='a',\n",
    "                                    header=header_t_or_f,\n",
    "                                    index=False)\n",
    "\n",
    "\n",
    "    def apply_lambda_save_csv(self) -> None:\n",
    "        \"\"\"\n",
    "        Apply lambda function on each row of input DataFrame and save the corresponding GPT model completion as a CSV file.\n",
    "        \"\"\"\n",
    "\n",
    "        ret = self.df.apply(lambda df_row: self.gpt_prompt_save_csv(df_row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = jobPostIingest(job_descr_path, gpt_output_path).ingest_jp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  d:\\\\\\\\project\\\\\\\\ai_job_autopilot\\\\\\\\gitlab\\\\\\\\ai_core\\\\\\\\data\\\\\\\\job_posts\\\\\\\\artifacts\\\\\\\\gpt_models\\\\ggml-gpt4all-j-v1.3-groovy.bin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = gpt4All(gpt_model_str, model_path)\n",
    "gpt = gptPredict(df, model, system_string, user_string, gpt_output_path)\n",
    "gpt.apply_lambda_save_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>companyName</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>salaries</th>\n",
       "      <th>hard_skills_ggml-gpt4all-j-v1.3-groovy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>IGT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>IGT (NYSE:IGT) is a global leader in gaming. W...</td>\n",
       "      <td>[{'link': 'https://www.glassdoor.ca/Salary/CIB...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title companyName     location  \\\n",
       "517  Data Scientist I         IGT    Canada      \n",
       "\n",
       "                                           description  \\\n",
       "517  IGT (NYSE:IGT) is a global leader in gaming. W...   \n",
       "\n",
       "                                              salaries  \\\n",
       "517  [{'link': 'https://www.glassdoor.ca/Salary/CIB...   \n",
       "\n",
       "    hard_skills_ggml-gpt4all-j-v1.3-groovy  \n",
       "517                                    NaN  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai_core'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobauto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
